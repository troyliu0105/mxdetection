trainer:
  amp: true
  ctx: &ctx 0
  epochs: 153
  batch_size: 8
  workers: 8
  hybridize: true
  log_interval: 100
  val_interval: 1
  save_interval: 1
  max_save: 10
  accumulate: 1
  train_metrics:
    - type: Loss
      name: loss
    - type: CustomLoss
      λtransform_fn: "lambda loss: [l[0] for l in loss]"
      name: box
    - type: CustomLoss
      λtransform_fn: "lambda loss: [l[1] for l in loss]"
      name: conf
    - type: CustomLoss
      λtransform_fn: "lambda loss: [l[2] for l in loss]"
      name: clz
    - type: IoUMetric
      name: iou
    - type: IoURecall
      iou_thres: 0.75
      name: recall75
detector:
  type: YOLOv3
  anchors: &anchors [ [ 33, 48, 50, 108, 127, 96 ],
                      [ 78, 202, 178, 179, 130, 295 ],
                      [ 332, 195, 228, 326, 366, 359 ] ]
  #  anchors: &anchors [ [ 25.81529033,  38.3634057 , 44.55140972,  93.6911521 , 113.57834053,  86.69660521 ],
  #                      [ 71.87384844, 188.29211426 , 168.47284698, 165.02140808,  121.92860794, 285.65744972 ],
  #                      [ 324.87639427, 189.16629314, 218.2322731 , 318.60364532, 363.08363152, 355.22986984 ] ]
  strides: &strides [ 8, 16, 32 ]
  num_class: &num_class 20
  backbone_cfg:
    backend: gluoncv
    name: mobilenetv3_large
    #pretrained: true
    pretrained: assets/0.2378-imagenet-mobilenetv3_large-0-best.params
    ctx: *ctx
    features:
      - _resunit6_hardswish0__mul0
      - _resunit12_hardswish0__mul0
      - hardswish1__mul0
  neck_cfg:
    type: RecalibratedBiFPN
    channels: 128
    repeats: 4
    pre_conv: true
    cbam: true
    cbam_reduction: 16
    cbam_expand_dilate: false
    expand_channels: false
    weighted_add: true
  head_cfg:
    type: YOLOv3Head
    anchors: *anchors
    strides: [ 8, 16, 32 ]
    num_classes: *num_class
loss:
  assigner_cfg:
    type: YOLOv3Assigner
    use_bbox_target: &use_bbox_target true
    num_class: *num_class
    label_smooth: false
    ignore_iou: 0.5
    obj_pos_weight: 1.0
    obj_neg_weight: 0.5
  bbox_loss_cfg:
    type: IoULoss
    loss_type: giou
    weight: 5.0
  conf_loss_cfg:
    type: BCE
  clz_loss_cfg:
    type: BCE
optimizer:
  type: sgd
  optimizer_params:
    learning_rate: &lr 0.001
    wd: 0.0005
    momentum: 0.9
  lr_scheduler:
    - mode: linear
      base_lr: 0
      target_lr: *lr
      nepochs: 3
      # 16551 / batch_size
      # iters_per_epoch: &iters_epoch 1035  # batchsize: 16
      # iters_per_epoch: &iters_epoch 2069  # batchsize: 8
      iters_per_epoch: &iters_epoch 2069
    - mode: step
      base_lr: *lr
      nepochs: 150
      iters_per_epoch: *iters_epoch
      step_factor: 0.1
      step_epoch: [ 120, 135 ]
      power: 2
  #    - type: CosineAnnealingScheduler
  #      eta_min: 0.0
  #      eta_max: 0.1
  #      nepochs: 150
  #      iters_per_epoch: 2069
  #      step_epoch: [ 4, 8, 16, 32, 64, 150 ]
  backbone_lr_mult: 0.1
  backbone_wd_mult: 0.1
  no_wd: false
dataset:
  train:
    type: VOCDetectionRecordFile
    filename: data/trainval.rec
  train_transform:
    multiscale_iter: 10
    transforms:
      #      - type: YOLOv3DefaultTransform
      #        height: 320
      #        width: 320
      #        mean: &mean [ 0.485, 0.456, 0.406 ]
      #        std: &std [ 0.229, 0.224, 0.225 ]
      - - type: YOLOv3DefaultTransform
          height: 320
          width: 320
          mean: &mean [ 0.485, 0.456, 0.406 ]
          std: &std [ 0.229, 0.224, 0.225 ]
      - - type: YOLOv3DefaultTransform
          height: 352
          width: 352
          mean: *mean
          std: *std
      - - type: YOLOv3DefaultTransform
          height: 384
          width: 384
          mean: *mean
          std: *std
      - - type: YOLOv3DefaultTransform
          height: 416
          width: 416
          mean: *mean
          std: *std
      - - type: YOLOv3DefaultTransform
          height: 448
          width: 448
          mean: *mean
          std: *std
      - - type: YOLOv3DefaultTransform
          height: 480
          width: 480
          mean: *mean
          std: *std
      - - type: YOLOv3DefaultTransform
          height: 512
          width: 512
          mean: *mean
          std: *std
      - - type: YOLOv3DefaultTransform
          height: 544
          width: 544
          mean: *mean
          std: *std
      - - type: YOLOv3DefaultTransform
          height: 576
          width: 576
          mean: *mean
          std: *std
      - - type: YOLOv3DefaultTransform
          height: 608
          width: 608
          mean: *mean
          std: *std
    generator:
      type: YOLOv3TargetGenerator
      num_class: *num_class
      strides: *strides
      anchors: *anchors
      use_secondary_anchors: false
      secondary_iou: 0.5
      use_bbox_target: *use_bbox_target
  test:
    type: VOCDetectionRecordFile
    filename: data/test.rec
    metric: voc07
  test_transform:
    - type: ToNumpy
    - type: Albumentations
      transforms:
        - type: Resize
          height: 416
          width: 416
      bbox_params:
        format: pascal_voc
    - type: ToTensor
    - type: Normalize
