trainer:
  amp: false
  ctx: &ctx 0
  epochs: 150
  batch_size: 8
  workers: 8
  hybridize: true
  log_interval: 100
  val_interval: 1
  save_interval: 1
  max_save: 10
  accumulate: 1
  train_metrics:
    - type: Loss
      name: loss
    - type: CustomLoss
      λtransform_fn: "lambda loss: [l[0] for l in loss]"
      name: box
    - type: CustomLoss
      λtransform_fn: "lambda loss: [l[1] for l in loss]"
      name: conf
    - type: CustomLoss
      λtransform_fn: "lambda loss: [l[2] for l in loss]"
      name: clz
    - type: IoUMetric
      name: iou
    - type: IoURecall
      iou_thres: 0.75
      name: recall75
detector:
  type: YOLOv3
  anchors: &anchors [ [ 33, 48, 50, 108, 127, 96 ],
                      [ 78, 202, 178, 179, 130, 295 ],
                      [ 332, 195, 228, 326, 366, 359 ] ]
  #  anchors: &anchors [ [ 25.81529033,  38.3634057 , 44.55140972,  93.6911521 , 113.57834053,  86.69660521 ],
  #                      [ 71.87384844, 188.29211426 , 168.47284698, 165.02140808,  121.92860794, 285.65744972 ],
  #                      [ 324.87639427, 189.16629314, 218.2322731 , 318.60364532, 363.08363152, 355.22986984 ] ]
  strides: &strides [ 8, 16, 32 ]
  num_class: &num_class 20
  backbone_cfg:
    backend: gluoncv
    name: mobilenetv3_large
    pretrained: true
    #    pretrained: assets/0.2378-imagenet-mobilenetv3_large-0-best.params
    ctx: *ctx
    features:
      - _resunit6_hardswish0__mul0
      - _resunit12_hardswish0__mul0
      - hardswish1__mul0
  neck_cfg:
    type: RecalibratedBiFPN
    channels: 256
    repeats: 4
    pre_conv: true
    cbam: false
    cbam_reduction: 16
    cbam_expand_dilate: false
    expand_channels: false
    weighted_add: true
  head_cfg:
    type: YOLOv3Head
    anchors: *anchors
    strides: [ 8, 16, 32 ]
    num_classes: *num_class
loss:
  type: YOLOv3Loss
#  class_num: *num_class
#  label_smooth: false
optimizer:
  type: adam
  optimizer_params:
    learning_rate: &lr 0.001
    wd: 0.0005
  lr_scheduler:
    - mode: linear
      base_lr: 0
      target_lr: *lr
      nepochs: 3
      # 16551 / batch_size
      # iters_per_epoch: &iters_epoch 1035  # batchsize: 16
      # iters_per_epoch: &iters_epoch 2069  # batchsize: 8
      iters_per_epoch: &iters_epoch 2069
    - mode: step
      base_lr: *lr
      nepochs: 150
      iters_per_epoch: *iters_epoch
      step_factor: 0.1
      step_epoch: [ 120, 135 ]
      power: 2
  backbone_lr_mult: 0.1
  backbone_wd_mult: 0.1
  no_wd: false
dataset:
  train:
    type: VOCDetectionRecordFile
    filename: data/trainval.rec
  train_transform:
    multiscale_iter: 10
    transforms:
      - - type: YOLOv3DefaultTransform
          height: 320
          width: 320
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - &generator
          type: YOLOv3TargetGenerator
          num_class: 20
          strides: *strides
          anchors: *anchors
      - - type: YOLOv3DefaultTransform
          height: 352
          width: 352
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
      - - type: YOLOv3DefaultTransform
          height: 384
          width: 384
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
      - - type: YOLOv3DefaultTransform
          height: 416
          width: 416
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
      - - type: YOLOv3DefaultTransform
          height: 448
          width: 448
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
      - - type: YOLOv3DefaultTransform
          height: 480
          width: 480
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
      - - type: YOLOv3DefaultTransform
          height: 512
          width: 512
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
      - - type: YOLOv3DefaultTransform
          height: 544
          width: 544
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
      - - type: YOLOv3DefaultTransform
          height: 576
          width: 576
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
      - - type: YOLOv3DefaultTransform
          height: 608
          width: 608
          mean: [ 0.485, 0.456, 0.406 ]
          std: [ 0.229, 0.224, 0.225 ]
        - *generator
  test:
    type: VOCDetectionRecordFile
    filename: data/test.rec
    metric: voc07
  test_transform:
    - type: ToNumpy
    - type: Albumentations
      transforms:
        - type: Resize
          height: 416
          width: 416
      bbox_params:
        format: pascal_voc
    - type: ToTensor
    - type: Normalize